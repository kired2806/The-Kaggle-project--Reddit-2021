{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet Kaggle Vf.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vQoEaKB80dxi",
        "5iBkhTQh028H",
        "kJrQNVki2ySZ",
        "092sK7_yel5A",
        "z-MQGLNnyvqJ",
        "dgyH-z8OzOm6",
        "-glHdzRk0Lgy",
        "rq7p2FuZX5oD",
        "HYm4UJrp8c5o",
        "ihhUsP-RRwxi",
        "2ydL4ap5cPXs",
        "WcK8tzlMfjl4",
        "hy3GgkOYfvOc",
        "oQ6mF7_jf4wl",
        "9yXzaAEVgEVs",
        "DzMg3j1cgKqH",
        "y0KCgLvwgSsS",
        "95W6dCXdJCkC",
        "OeM-CmDqmEGC",
        "9lZ2lNyJNQAW",
        "usmXQkQXNDaB",
        "CURMpD9hRoQs",
        "rjdCm-hx9F8L",
        "PiKn3Q-19Jxp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9C5DrfF0S61"
      },
      "source": [
        "Créé le 9 février 2021\n",
        "\n",
        "**Compétition Kaggle** \n",
        "\n",
        "**Team : Les Kagglettes**\n",
        " \n",
        "Auteurs : KIRED Nour & ROSSI Valentine\n",
        "\n",
        "Promo : M1 SID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A4NSBOs0U1_"
      },
      "source": [
        "# Récupération des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQoEaKB80dxi"
      },
      "source": [
        "## Lien entre Colab et le Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfw1-E8d0Srf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75f8714-3d4f-421e-ef97-43f28be9cbc5"
      },
      "source": [
        "# lien avec Colab\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3J5rKcN0xIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eff7104-66de-44e4-f157-806a9dbc53cc"
      },
      "source": [
        "# création de la date\n",
        "import os.path, time\n",
        "print(\"created: %s\" % time.ctime(os.path.getctime(\"/content/drive/MyDrive/kaggle Project/Données/comments_students.csv\"))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created: Tue Feb  9 18:43:35 2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iBkhTQh028H"
      },
      "source": [
        "## Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QACos2dr0J63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9d34ca-d0a4-49c5-e326-93dc6eff1279"
      },
      "source": [
        "# installations de librairies\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=f081a8093abbeab3e8b51a171e9e25e3e83bb6c86d68e50e1c9426d31c34eb76\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWa2eangxVMq"
      },
      "source": [
        "import random\n",
        "# Modele lgbm\n",
        "import lightgbm as lgb\n",
        "import sklearn\n",
        "\n",
        "# Reseau\n",
        "from pprint import pprint\n",
        "import networkx as nx\n",
        "from textblob import Word\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QQp6kku0Tld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89293b18-3dcc-4367-d37f-bbdfc55587cb"
      },
      "source": [
        "# PARTIE TRAITEMENT DE TEXTE\n",
        "\n",
        "# Maths\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "#  traitement de texte\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopWords=stopwords.words('english')\n",
        "\n",
        "# Traitement du langage et recherche d'informations\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Modeles de prediction \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLat0jrg1dEZ"
      },
      "source": [
        "# Pas de message d'alerte\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### barre de chargement\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWO5wAkN12MR"
      },
      "source": [
        "## Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnY9_gd0xwF0"
      },
      "source": [
        "## importation des chemins et données utiles\n",
        "feature_dossier = \"/content/drive/MyDrive/kaggle Project/Données/Data_Feature/\"\n",
        "comments_students = \"/content/drive/MyDrive/kaggle Project/Données/comments_students.csv\"\n",
        "tests=\"/content/drive/MyDrive/kaggle Project/tests\"\n",
        "all_feature=feature_dossier + \"data_all_feature.csv\"\n",
        "df_fin = pd.read_csv(comments_students)[['ups', 'id']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1TqMF4-2dBp"
      },
      "source": [
        "# **PARTIE 1**: Exploration et traitement des données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJrQNVki2ySZ"
      },
      "source": [
        "## Description et affichage des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp5SkS2NZ61t"
      },
      "source": [
        "## lecture du fichier csv\n",
        "data=pd.read_csv(comments_students)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkD1F-VR2gex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f57287-cc75-49e7-8595-513e4d9d5507"
      },
      "source": [
        "# Lecture de 5 lignes de manière aléatoire\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 1685272,\n            'f': \"1685272\",\n        },\n{\n            'v': 1431534668,\n            'f': \"1431534668\",\n        },\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n\"t5_2qh1i\",\n\"t3_35u9yx\",\n\"t1_cr7vm6i\",\n\"AskReddit\",\n\"cr7vm6i\",\n\"crazu\",\n\"I still use my parents old TomTom from 2004. I always plan any new journeys on maps/atlas', but for the 'get you to the doorstep' ability, GPS is simply revolutionary.\",\n\"t1_cr7vbx2\"],\n [{\n            'v': 2256604,\n            'f': \"2256604\",\n        },\n{\n            'v': 1431891616,\n            'f': \"1431891616\",\n        },\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n\"t5_2qh1i\",\n\"t3_36959m\",\n\"t1_crc700d\",\n\"AskReddit\",\n\"crc700d\",\n\"Ragnar_The_Dane\",\n\"The purpose of a justice system is first and foremost to protect society. Thus you remove individuals from society who have caused harm or have attempted to. It also acts as a deterrent for others to do similar acts.  The secondary and lesser purpose is the revenge aspect. It also has to exist to some extent otherwise the people who have been harmed by an individual may decide to take matters into their own hands which is undesirable.  This is why a system of rehabilitation is much more desirable. You want to return people to society so they can contribute again rather than lock them up for years on end and have them come out and simply harm society again due to not being rehabilitated. \",\n\"t1_crc6ugp\"],\n [{\n            'v': 4112155,\n            'f': \"4112155\",\n        },\n{\n            'v': 1433034572,\n            'f': \"1433034572\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n\"t5_2qh1i\",\n\"t3_37wocp\",\n\"t1_crqefop\",\n\"AskReddit\",\n\"crqefop\",\n\"Y_dilligaf\",\n\"I'm talking, post birth 2 fully developed human babies, tie the hands together, and watch it grow. Make a chain out of these kids, I don't care. Just post birth\",\n\"t1_crqeb3o\"],\n [{\n            'v': 3156424,\n            'f': \"3156424\",\n        },\n{\n            'v': 1432467745,\n            'f': \"1432467745\",\n        },\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n\"t5_2qh1i\",\n\"t3_372xmv\",\n\"t1_crj8vvo\",\n\"AskReddit\",\n\"crj8vvo\",\n\"MyHeadIsNotRight\",\n\"God\",\n\"t3_372xmv\"],\n [{\n            'v': 552494,\n            'f': \"552494\",\n        },\n{\n            'v': 1430831729,\n            'f': \"1430831729\",\n        },\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n\"t5_2qh1i\",\n\"t3_34t9e9\",\n\"t1_cqz16lo\",\n\"AskReddit\",\n\"cqz16lo\",\n\"honeybadgergrrl\",\n\"Yeah, she probably brought home more money than he did. \",\n\"t1_cqyt8kr\"]],\n        columns: [[\"number\", \"index\"], [\"number\", \"created_utc\"], [\"number\", \"ups\"], [\"string\", \"subreddit_id\"], [\"string\", \"link_id\"], [\"string\", \"name\"], [\"string\", \"subreddit\"], [\"string\", \"id\"], [\"string\", \"author\"], [\"string\", \"body\"], [\"string\", \"parent_id\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>ups</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>link_id</th>\n",
              "      <th>name</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>parent_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1685272</th>\n",
              "      <td>1431534668</td>\n",
              "      <td>2.0</td>\n",
              "      <td>t5_2qh1i</td>\n",
              "      <td>t3_35u9yx</td>\n",
              "      <td>t1_cr7vm6i</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>cr7vm6i</td>\n",
              "      <td>crazu</td>\n",
              "      <td>I still use my parents old TomTom from 2004. I...</td>\n",
              "      <td>t1_cr7vbx2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2256604</th>\n",
              "      <td>1431891616</td>\n",
              "      <td>3.0</td>\n",
              "      <td>t5_2qh1i</td>\n",
              "      <td>t3_36959m</td>\n",
              "      <td>t1_crc700d</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>crc700d</td>\n",
              "      <td>Ragnar_The_Dane</td>\n",
              "      <td>The purpose of a justice system is first and f...</td>\n",
              "      <td>t1_crc6ugp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4112155</th>\n",
              "      <td>1433034572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>t5_2qh1i</td>\n",
              "      <td>t3_37wocp</td>\n",
              "      <td>t1_crqefop</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>crqefop</td>\n",
              "      <td>Y_dilligaf</td>\n",
              "      <td>I'm talking, post birth 2 fully developed huma...</td>\n",
              "      <td>t1_crqeb3o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3156424</th>\n",
              "      <td>1432467745</td>\n",
              "      <td>2.0</td>\n",
              "      <td>t5_2qh1i</td>\n",
              "      <td>t3_372xmv</td>\n",
              "      <td>t1_crj8vvo</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>crj8vvo</td>\n",
              "      <td>MyHeadIsNotRight</td>\n",
              "      <td>God</td>\n",
              "      <td>t3_372xmv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552494</th>\n",
              "      <td>1430831729</td>\n",
              "      <td>2.0</td>\n",
              "      <td>t5_2qh1i</td>\n",
              "      <td>t3_34t9e9</td>\n",
              "      <td>t1_cqz16lo</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>cqz16lo</td>\n",
              "      <td>honeybadgergrrl</td>\n",
              "      <td>Yeah, she probably brought home more money tha...</td>\n",
              "      <td>t1_cqyt8kr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         created_utc  ...   parent_id\n",
              "1685272   1431534668  ...  t1_cr7vbx2\n",
              "2256604   1431891616  ...  t1_crc6ugp\n",
              "4112155   1433034572  ...  t1_crqeb3o\n",
              "3156424   1432467745  ...   t3_372xmv\n",
              "552494    1430831729  ...  t1_cqyt8kr\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbFiUoSwaPCw"
      },
      "source": [
        "##### partie exploration des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5vmctvi2-Nt"
      },
      "source": [
        "# Affichage du type des colonnes\n",
        "data.dtypes \n",
        "# Supprission de data pour ne pas consommer bcp d'espace de Ram\n",
        "del data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EpiBhP13GL_"
      },
      "source": [
        "**Description des colonnes :**\n",
        "- created_utc : heure de création (format heure UTC seconde)\n",
        "- ups : score du commentaire, c'est l'attribut à prédire.\n",
        "- subreddit_id : identifiant du subreddit dans lequel se trouve l'objet\n",
        "- link_id : identifiant du lien dans lequel se trouve le commentaire\n",
        "- name : nom complet du commentaire\n",
        "- subreddit : subreddit de chose excluant le / r / pre x. \\photos\"\n",
        "- id : identifiant de l'article\n",
        "- author : nom du compte de l'affiche\n",
        "- body : texte brut (texte non formaté qui inclut les caractères de balisage brut tels que ** pour gras)\n",
        "- parent_id : identifiant de l'élément auquel le commentaire est une réponse, qu'il s'agisse du lien ou du commentaire qu'il contient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkqQFm-lyhkt"
      },
      "source": [
        "## Creation des features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "092sK7_yel5A"
      },
      "source": [
        "#### 1er feature (closeness)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jNzLWhAyFT_"
      },
      "source": [
        "# Chargement des données et suppression de colonnes inutiles\n",
        "df = pd.read_csv(comments_students).drop(columns=['subreddit_id', 'subreddit', 'id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIUdkrMuyOtX"
      },
      "source": [
        "# Création du graph\n",
        "g = nx.DiGraph()\n",
        "g.add_nodes_from(df.link_id, type=\"link\")\n",
        "g.add_nodes_from(df.name, type=\"comment\")\n",
        "g.add_edges_from(df[[\"name\", \"parent_id\"]].values, link_type=\"parent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vbID2zPCgzO"
      },
      "source": [
        "# Features correspondantes\n",
        "close_cent = nx.degree_centrality(g)\n",
        "closeness = pd.DataFrame()\n",
        "closeness['close_cent'] = [close_cent[x] for x in df[\"name\"]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyST-RqAypgQ"
      },
      "source": [
        "# Features correspondantes\n",
        "close_cent = nx.degree_centrality(g)\n",
        "closeness = pd.DataFrame()\n",
        "closeness['close_cent'] = [close_cent[x] for x in df[\"name\"]]\n",
        "closeness.to_csv(feature_dossier + \"closeness.csv\")\n",
        "\n",
        "del g, close_cent, closeness,df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-MQGLNnyvqJ"
      },
      "source": [
        "#### 2e feature (closeness_author)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOYvgw7GyyPe"
      },
      "source": [
        "# Chargement des données avec les colonnes utiles\n",
        "df = pd.read_csv(comments_students)[['name', 'author', 'parent_id', 'link_id']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6lDxs_ry6Qm"
      },
      "source": [
        "# Features correspondantes\n",
        "dic_aut_name : dict = {df['name'].iloc[i]: df['author'].iloc[i] for i in range(len(df))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNQxoZD5zDcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786ae5c5-64b1-460f-bcb7-686bfd64a09d"
      },
      "source": [
        "liste : list = []\n",
        "for i in tqdm(df['parent_id'].values):\n",
        "    if i in dic_aut_name.keys():\n",
        "        liste.append(dic_aut_name[i])\n",
        "    else:\n",
        "        liste.append(i)\n",
        "df['new_parent_id'] : list= liste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4234970/4234970 [00:04<00:00, 1021800.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnno52fozEph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8355cb3-cfab-4b57-92c8-1ef3e501fb92"
      },
      "source": [
        "# Création du graph\n",
        "g_di = nx.DiGraph()\n",
        "g_di.add_nodes_from(df.link_id, type=\"link\")\n",
        "g_di.add_nodes_from(df.author, type=\"comment\")\n",
        "g_di.add_edges_from(df[[\"author\", \"new_parent_id\"]].values)\n",
        "\n",
        "close_cent = nx.degree_centrality(g_di)\n",
        "\n",
        "df['close_cent_aut'] = [close_cent[i] for i in tqdm(df['author'].values)]\n",
        "df = pd.DataFrame(df['close_cent_aut'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4234970/4234970 [00:02<00:00, 1585336.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3x-Z2P7zK3x"
      },
      "source": [
        "# Exportation des features\n",
        "df.to_csv(feature_dossier + \"closeness_author.csv\")\n",
        "del df, dic_aut_name, liste, i, g_di, close_cent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgyH-z8OzOm6"
      },
      "source": [
        "#### 3e feature ( betweenness_centrality_author)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXhopLfUzR17"
      },
      "source": [
        "# Chargement des données avec les colonnes utiles\n",
        "df = pd.read_csv(comments_students)[['name', 'author', 'parent_id', 'link_id']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBwAqJFIzYrN"
      },
      "source": [
        "# Features correspondantes\n",
        "dic_aut_name : dict = {df['name'].iloc[i]: df['author'].iloc[i]\n",
        "                for i in range(len(df))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GstTQmEHzbwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae6e734-47d1-42cb-cce6-db274b2360e2"
      },
      "source": [
        "liste : list = []\n",
        "for i in tqdm(df['parent_id'].values):\n",
        "    if i in dic_aut_name.keys():\n",
        "        liste.append(dic_aut_name[i])\n",
        "    else:\n",
        "        liste.append(i)\n",
        "df['new_parent_id'] : list = liste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4234970/4234970 [00:04<00:00, 1026750.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaujIRPDzeAs"
      },
      "source": [
        "# Création du graph\n",
        "g_di = nx.DiGraph()\n",
        "g_di.add_nodes_from(df.link_id, type=\"link\")\n",
        "g_di.add_nodes_from(df.author, type=\"comment\")\n",
        "g_di.add_edges_from(df[[\"author\", \"new_parent_id\"]].values)\n",
        "\n",
        "bet_cent = nx.betweenness_centrality(g_di, k=100)\n",
        "bet_cent_aut = pd.DataFrame([bet_cent[i] for i in tqdm(\n",
        "    df['author'].values)], columns=['bet_cent_aut'])\n",
        "bet_cent_aut = bet_cent_aut['bet_cent_aut']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7dF9pI3zhgJ"
      },
      "source": [
        "# Exportation des features\n",
        "bet_cent_aut.to_csv(feature_dossier + \"betweenness_centrality_author.csv\")\n",
        "del df, dic_aut_name, liste, i, g_di, bet_cent_aut"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-glHdzRk0Lgy"
      },
      "source": [
        "#### 4e feature(comment_depth) ( trop long )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AyYZi4lDt3w"
      },
      "source": [
        "feature pensée, mais malheuresement on a pas pu l'executer car trop long."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YuR1yX0z2BQ"
      },
      "source": [
        "def it_prof(dic_name_depth, prof, list_noeud):\n",
        "    for tt in list_noeud:\n",
        "        if prof == 0 and tt[1] == '1':\n",
        "            prof += 2\n",
        "        dic_name_depth.update({tt: prof})\n",
        "        it_prof(dic_name_depth, prof+1, list(g.predecessors(tt)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAQy7Le0z37A"
      },
      "source": [
        "df = pd.read_csv(comments_students)[['link_id', 'name', 'parent_id']]\n",
        "liste_unique_link = np.unique(df['link_id'])\n",
        "dic_name_depth : dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzI-9HM2z5oj"
      },
      "source": [
        "for link in tqdm(liste_unique_link):\n",
        "    df2 = df[df['link_id'] == link]\n",
        "    g = nx.DiGraph()\n",
        "    g.add_nodes_from(df2.link_id, type=\"link\")\n",
        "    g.add_nodes_from(df2.name, type=\"comment\")\n",
        "    g.add_edges_from(df2[[\"name\", \"parent_id\"]].values)\n",
        "    list_noeud = [node for node in list(\n",
        "        g.nodes()) if list(g.neighbors(node)) == []]\n",
        "    prof : int = 0\n",
        "    it_prof(dic_name_depth, prof, list_noeud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E14MNoCIz7dR"
      },
      "source": [
        "df['com_depth'] = [dic_name_depth[i] for i in df['name'].values]\n",
        "df[['com_depth']].to_csv(feature_dossier + 'comment_depth.csv')\n",
        "\n",
        "del df, g, liste_unique_link, dic_name_depth, df2, link, prof, list_noeud, it_prof"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJn_0UAX9l_"
      },
      "source": [
        "#### 5e Feature (creaction des topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq7p2FuZX5oD"
      },
      "source": [
        "##### Fonctions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUKM-9jdXpY1"
      },
      "source": [
        "def cleanedWords(raw_sentence):\n",
        "  \"\"\"Documentation\n",
        "    Parameters:\n",
        "        raw_sentence: un commentaire (une ligne qui correspond à un commentaire du fichier csv)\n",
        "    Out:\n",
        "        le commentaire nettoyé en supprimant les chiffres les caracteres speciaux ainsi qu'en le mettant en miniscule\n",
        "    \"\"\"\n",
        "    return (re.sub(\"[^a-zA-Z]\", \" \", raw_sentence.lower()))\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    \"\"\"\"Documentation\n",
        "      Parameters:\n",
        "            textes : les bodies\n",
        "      Out :\n",
        "            les bodies sans mots vides\n",
        "\n",
        "    \"\"\"\n",
        "    return [word for word in simple_preprocess(texts) if word not in stopWords] \n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    words = []\n",
        "    for sentence in tqdm(sentences):\n",
        "        words.append(str(sentence).split())  \n",
        "    return words\n",
        "        \n",
        "def lemmatization(texts):\n",
        "\n",
        "    texts_out = []\n",
        "    for sent in tqdm(texts):\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc])\n",
        "    return texts_out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYm4UJrp8c5o"
      },
      "source": [
        "##### Nettoyage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRVLBgbZRQNo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b3ae917-aa61-4327-fd8c-62df0204c2d6"
      },
      "source": [
        "col_body : list = []\n",
        "chunksize : int  = 10 ** 5\n",
        "\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(\"/content/drive/MyDrive/M1 SID/kaggle Project/Données/comments_students.csv\", chunksize=chunksize)):\n",
        "    chunk = chunk.astype({'body': str})\n",
        "    print(\"chunk \", i, \" begin\")\n",
        "    data_words = [cleanedWords(sentence) for sentence in tqdm(chunk['body'].values)]\n",
        "    print(\"chunk \", i, \"data_words ok\")\n",
        "\n",
        "    # Remove Stop Words\n",
        "    data_words_nostops = []\n",
        "    for doc in tqdm(data_words):\n",
        "      result=remove_stopwords(doc)\n",
        "      if result!=[]:\n",
        "        data_words_nostops.append(result)\n",
        "      else :\n",
        "        data_words_nostops.append([doc])\n",
        "\n",
        "    print(\"chunk \", i, \"data_words_nostops ok\")\n",
        "\n",
        "    # Do lemmatization keeping \n",
        "    data_lemmatized = lemmatization(data_words_nostops)\n",
        "\n",
        "    print(\"chunk \", i, \"data_lemmatized ok\")\n",
        "\n",
        "    col_body += data_lemmatized\n",
        "    print(\"chunk \", i, \" ok\")\n",
        "\n",
        "\n",
        "del i, chunk, chunksize, data_words, data_words_nostops, data_lemmatized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/100000 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▏        | 12483/100000 [00:00<00:00, 124827.44it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "chunk  0  begin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 24%|██▎       | 23640/100000 [00:00<00:00, 120443.70it/s]\u001b[A\n",
            " 36%|███▌      | 35837/100000 [00:00<00:00, 120891.00it/s]\u001b[A\n",
            " 48%|████▊     | 47655/100000 [00:00<00:00, 120038.60it/s]\u001b[A\n",
            " 59%|█████▉    | 59169/100000 [00:00<00:00, 118525.66it/s]\u001b[A\n",
            " 69%|██████▉   | 69318/100000 [00:00<00:00, 112839.97it/s]\u001b[A\n",
            " 79%|███████▉  | 79203/100000 [00:00<00:00, 105028.07it/s]\u001b[A\n",
            "100%|██████████| 100000/100000 [00:00<00:00, 110044.78it/s]\n",
            "\n",
            "  0%|          | 0/100000 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1280/100000 [00:00<00:07, 12748.80it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "chunk  0 data_words ok\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  2%|▏         | 2405/100000 [00:00<00:07, 12254.35it/s]\u001b[A\n",
            "  4%|▎         | 3562/100000 [00:00<00:08, 12038.31it/s]\u001b[A\n",
            "  5%|▍         | 4767/100000 [00:00<00:07, 12039.15it/s]\u001b[A\n",
            "  6%|▌         | 5952/100000 [00:00<00:07, 11979.48it/s]\u001b[A\n",
            "  7%|▋         | 7022/100000 [00:00<00:08, 11561.54it/s]\u001b[A\n",
            "  8%|▊         | 8231/100000 [00:00<00:07, 11712.85it/s]\u001b[A\n",
            "  9%|▉         | 9301/100000 [00:00<00:08, 11301.10it/s]\u001b[A\n",
            " 10%|█         | 10461/100000 [00:00<00:07, 11383.95it/s]\u001b[A\n",
            " 12%|█▏        | 11553/100000 [00:01<00:07, 11134.92it/s]\u001b[A\n",
            " 13%|█▎        | 12635/100000 [00:01<00:07, 11003.16it/s]\u001b[A\n",
            " 14%|█▎        | 13744/100000 [00:01<00:07, 11028.83it/s]\u001b[A\n",
            " 15%|█▍        | 14832/100000 [00:01<00:07, 10958.70it/s]\u001b[A\n",
            " 16%|█▌        | 15962/100000 [00:01<00:07, 11056.79it/s]\u001b[A\n",
            " 17%|█▋        | 17094/100000 [00:01<00:07, 11133.88it/s]\u001b[A\n",
            " 18%|█▊        | 18203/100000 [00:01<00:07, 11061.67it/s]\u001b[A\n",
            " 19%|█▉        | 19306/100000 [00:01<00:07, 10981.57it/s]\u001b[A\n",
            " 20%|██        | 20402/100000 [00:01<00:07, 10827.18it/s]\u001b[A\n",
            " 22%|██▏       | 21597/100000 [00:01<00:07, 11140.66it/s]\u001b[A\n",
            " 23%|██▎       | 22782/100000 [00:02<00:06, 11341.82it/s]\u001b[A\n",
            " 24%|██▍       | 23919/100000 [00:02<00:06, 11253.77it/s]\u001b[A\n",
            " 25%|██▌       | 25046/100000 [00:02<00:06, 11101.59it/s]\u001b[A\n",
            " 26%|██▌       | 26158/100000 [00:02<00:06, 10886.24it/s]\u001b[A\n",
            " 27%|██▋       | 27422/100000 [00:02<00:06, 11353.45it/s]\u001b[A\n",
            " 29%|██▉       | 28764/100000 [00:02<00:05, 11902.77it/s]\u001b[A\n",
            " 30%|██▉       | 29966/100000 [00:02<00:05, 11778.91it/s]\u001b[A\n",
            " 31%|███       | 31153/100000 [00:02<00:05, 11526.51it/s]\u001b[A\n",
            " 32%|███▏      | 32313/100000 [00:02<00:05, 11500.84it/s]\u001b[A\n",
            " 34%|███▎      | 33525/100000 [00:02<00:05, 11676.07it/s]\u001b[A\n",
            " 35%|███▍      | 34697/100000 [00:03<00:05, 11674.63it/s]\u001b[A\n",
            " 36%|███▌      | 35868/100000 [00:03<00:05, 11154.33it/s]\u001b[A\n",
            " 37%|███▋      | 36991/100000 [00:03<00:05, 11077.18it/s]\u001b[A\n",
            " 38%|███▊      | 38104/100000 [00:03<00:05, 11045.58it/s]\u001b[A\n",
            " 39%|███▉      | 39213/100000 [00:03<00:05, 11041.91it/s]\u001b[A\n",
            " 40%|████      | 40320/100000 [00:03<00:05, 10494.63it/s]\u001b[A\n",
            " 42%|████▏     | 41533/100000 [00:03<00:05, 10936.60it/s]\u001b[A\n",
            " 43%|████▎     | 42637/100000 [00:03<00:05, 10740.84it/s]\u001b[A\n",
            " 44%|████▍     | 43773/100000 [00:03<00:05, 10903.86it/s]\u001b[A\n",
            " 45%|████▍     | 44870/100000 [00:03<00:05, 10737.43it/s]\u001b[A\n",
            " 46%|████▌     | 46029/100000 [00:04<00:04, 10977.69it/s]\u001b[A\n",
            " 47%|████▋     | 47132/100000 [00:04<00:04, 10831.03it/s]\u001b[A\n",
            " 48%|████▊     | 48219/100000 [00:04<00:04, 10399.83it/s]\u001b[A\n",
            " 49%|████▉     | 49295/100000 [00:04<00:04, 10504.90it/s]\u001b[A\n",
            " 50%|█████     | 50391/100000 [00:04<00:04, 10630.39it/s]\u001b[A\n",
            " 51%|█████▏    | 51458/100000 [00:04<00:04, 10511.86it/s]\u001b[A\n",
            " 53%|█████▎    | 52513/100000 [00:04<00:04, 10492.31it/s]\u001b[A\n",
            " 54%|█████▎    | 53565/100000 [00:04<00:05, 7835.39it/s] \u001b[A\n",
            " 55%|█████▍    | 54773/100000 [00:05<00:05, 8756.89it/s]\u001b[A\n",
            " 56%|█████▌    | 55754/100000 [00:05<00:04, 8954.74it/s]\u001b[A\n",
            " 57%|█████▋    | 56909/100000 [00:05<00:04, 9552.94it/s]\u001b[A\n",
            " 58%|█████▊    | 58028/100000 [00:05<00:04, 9988.79it/s]\u001b[A\n",
            " 59%|█████▉    | 59100/100000 [00:05<00:04, 10193.79it/s]\u001b[A\n",
            " 60%|██████    | 60193/100000 [00:05<00:03, 10402.73it/s]\u001b[A\n",
            " 61%|██████▏   | 61260/100000 [00:05<00:03, 10157.65it/s]\u001b[A\n",
            " 62%|██████▏   | 62296/100000 [00:05<00:03, 10083.12it/s]\u001b[A\n",
            " 63%|██████▎   | 63319/100000 [00:05<00:03, 9851.75it/s] \u001b[A\n",
            " 64%|██████▍   | 64315/100000 [00:05<00:03, 9834.65it/s]\u001b[A\n",
            " 65%|██████▌   | 65307/100000 [00:06<00:03, 9509.02it/s]\u001b[A\n",
            " 66%|██████▋   | 66266/100000 [00:06<00:03, 9121.13it/s]\u001b[A\n",
            " 67%|██████▋   | 67187/100000 [00:06<00:03, 9106.08it/s]\u001b[A\n",
            " 68%|██████▊   | 68104/100000 [00:06<00:03, 9042.17it/s]\u001b[A\n",
            " 69%|██████▉   | 69013/100000 [00:06<00:03, 8760.19it/s]\u001b[A\n",
            " 70%|██████▉   | 69894/100000 [00:06<00:03, 8722.05it/s]\u001b[A\n",
            " 71%|███████   | 70770/100000 [00:06<00:03, 8503.68it/s]\u001b[A\n",
            " 72%|███████▏  | 71625/100000 [00:06<00:03, 7984.97it/s]\u001b[A\n",
            " 72%|███████▏  | 72486/100000 [00:06<00:03, 8160.54it/s]\u001b[A\n",
            " 73%|███████▎  | 73310/100000 [00:07<00:03, 8178.06it/s]\u001b[A\n",
            " 74%|███████▍  | 74133/100000 [00:07<00:03, 8044.74it/s]\u001b[A\n",
            " 75%|███████▍  | 74942/100000 [00:07<00:03, 8004.91it/s]\u001b[A\n",
            " 76%|███████▌  | 75862/100000 [00:07<00:02, 8325.05it/s]\u001b[A\n",
            " 77%|███████▋  | 76700/100000 [00:07<00:02, 8323.83it/s]\u001b[A\n",
            " 78%|███████▊  | 77537/100000 [00:07<00:02, 8315.33it/s]\u001b[A\n",
            " 78%|███████▊  | 78397/100000 [00:07<00:02, 8395.01it/s]\u001b[A\n",
            " 79%|███████▉  | 79301/100000 [00:07<00:02, 8552.11it/s]\u001b[A\n",
            " 80%|████████  | 80159/100000 [00:07<00:02, 8458.51it/s]\u001b[A\n",
            " 81%|████████  | 81007/100000 [00:07<00:02, 8365.27it/s]\u001b[A\n",
            " 82%|████████▏ | 81910/100000 [00:08<00:02, 8546.87it/s]\u001b[A\n",
            " 83%|████████▎ | 82820/100000 [00:08<00:01, 8693.91it/s]\u001b[A\n",
            " 84%|████████▎ | 83701/100000 [00:08<00:01, 8727.37it/s]\u001b[A\n",
            " 85%|████████▍ | 84680/100000 [00:08<00:01, 9019.41it/s]\u001b[A\n",
            " 86%|████████▌ | 85586/100000 [00:08<00:01, 8610.09it/s]\u001b[A\n",
            " 87%|████████▋ | 86569/100000 [00:08<00:01, 8942.54it/s]\u001b[A\n",
            " 87%|████████▋ | 87491/100000 [00:08<00:01, 9019.17it/s]\u001b[A\n",
            " 88%|████████▊ | 88459/100000 [00:08<00:01, 9203.62it/s]\u001b[A\n",
            " 89%|████████▉ | 89385/100000 [00:08<00:01, 8941.43it/s]\u001b[A\n",
            " 90%|█████████ | 90348/100000 [00:08<00:01, 9126.82it/s]\u001b[A\n",
            " 91%|█████████▏| 91321/100000 [00:09<00:00, 9298.05it/s]\u001b[A\n",
            " 92%|█████████▏| 92255/100000 [00:09<00:00, 9138.60it/s]\u001b[A\n",
            " 93%|█████████▎| 93173/100000 [00:09<00:00, 8967.86it/s]\u001b[A\n",
            " 94%|█████████▍| 94122/100000 [00:09<00:00, 9118.09it/s]\u001b[A\n",
            " 95%|█████████▌| 95037/100000 [00:09<00:00, 9021.25it/s]\u001b[A\n",
            " 96%|█████████▌| 95942/100000 [00:09<00:00, 8967.44it/s]\u001b[A\n",
            " 97%|█████████▋| 96984/100000 [00:09<00:00, 9358.76it/s]\u001b[A\n",
            " 98%|█████████▊| 97926/100000 [00:09<00:00, 9143.19it/s]\u001b[A\n",
            " 99%|█████████▉| 98846/100000 [00:09<00:00, 9101.38it/s]\u001b[A\n",
            "100%|██████████| 100000/100000 [00:10<00:00, 9941.18it/s]\n",
            "\n",
            "  0%|          | 0/100000 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 20/100000 [00:00<08:32, 195.05it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "chunk  0 data_words_nostops ok\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 35/100000 [00:00<09:33, 174.21it/s]\u001b[A\n",
            "  0%|          | 65/100000 [00:00<08:23, 198.40it/s]\u001b[A\n",
            "  0%|          | 90/100000 [00:00<07:58, 208.76it/s]\u001b[A\n",
            "  0%|          | 119/100000 [00:00<07:18, 227.75it/s]\u001b[A\n",
            "  0%|          | 150/100000 [00:00<06:44, 246.67it/s]\u001b[A\n",
            "  0%|          | 180/100000 [00:00<06:25, 259.05it/s]\u001b[A\n",
            "  0%|          | 206/100000 [00:00<06:44, 246.81it/s]\u001b[A\n",
            "  0%|          | 236/100000 [00:00<06:23, 260.39it/s]\u001b[A\n",
            "  0%|          | 263/100000 [00:01<06:20, 261.87it/s]\u001b[A\n",
            "  0%|          | 293/100000 [00:01<06:08, 270.62it/s]\u001b[A\n",
            "  0%|          | 321/100000 [00:01<06:15, 265.31it/s]\u001b[A\n",
            "  0%|          | 348/100000 [00:01<06:26, 257.59it/s]\u001b[A\n",
            "  0%|          | 377/100000 [00:01<06:14, 265.95it/s]\u001b[A\n",
            "  0%|          | 407/100000 [00:01<06:04, 273.45it/s]\u001b[A\n",
            "  0%|          | 436/100000 [00:01<06:00, 275.99it/s]\u001b[A\n",
            "  0%|          | 464/100000 [00:01<06:10, 268.59it/s]\u001b[A\n",
            "  0%|          | 491/100000 [00:01<06:10, 268.46it/s]\u001b[A\n",
            "  1%|          | 520/100000 [00:01<06:02, 274.17it/s]\u001b[A\n",
            "  1%|          | 548/100000 [00:02<06:14, 265.59it/s]\u001b[A\n",
            "  1%|          | 575/100000 [00:02<06:20, 261.45it/s]\u001b[A\n",
            "  1%|          | 608/100000 [00:02<05:57, 278.35it/s]\u001b[A\n",
            "  1%|          | 639/100000 [00:02<05:49, 284.43it/s]\u001b[A\n",
            "  1%|          | 669/100000 [00:02<05:46, 286.46it/s]\u001b[A\n",
            "  1%|          | 702/100000 [00:02<05:37, 294.44it/s]\u001b[A\n",
            "  1%|          | 733/100000 [00:02<05:32, 298.61it/s]\u001b[A\n",
            "  1%|          | 764/100000 [00:02<05:39, 292.38it/s]\u001b[A\n",
            "  1%|          | 794/100000 [00:02<05:54, 279.46it/s]\u001b[A\n",
            "  1%|          | 828/100000 [00:03<05:37, 294.27it/s]\u001b[A\n",
            "  1%|          | 860/100000 [00:03<05:29, 301.06it/s]\u001b[A\n",
            "  1%|          | 893/100000 [00:03<05:21, 307.83it/s]\u001b[A\n",
            "  1%|          | 927/100000 [00:03<05:13, 316.43it/s]\u001b[A\n",
            "  1%|          | 959/100000 [00:03<05:18, 310.74it/s]\u001b[A\n",
            "  1%|          | 991/100000 [00:03<05:17, 311.43it/s]\u001b[A\n",
            "  1%|          | 1023/100000 [00:03<05:28, 301.67it/s]\u001b[A\n",
            "  1%|          | 1054/100000 [00:03<05:28, 301.14it/s]\u001b[A\n",
            "  1%|          | 1085/100000 [00:03<05:30, 298.96it/s]\u001b[A\n",
            "  1%|          | 1119/100000 [00:03<05:25, 303.53it/s]\u001b[A\n",
            "  1%|          | 1154/100000 [00:04<05:12, 316.01it/s]\u001b[A\n",
            "  1%|          | 1186/100000 [00:04<05:20, 308.64it/s]\u001b[A\n",
            "  1%|          | 1218/100000 [00:04<05:26, 302.61it/s]\u001b[A\n",
            "  1%|          | 1249/100000 [00:04<05:33, 296.25it/s]\u001b[A\n",
            "  1%|▏         | 1279/100000 [00:04<05:36, 293.57it/s]\u001b[A\n",
            "  1%|▏         | 1309/100000 [00:04<05:46, 285.06it/s]\u001b[A\n",
            "  1%|▏         | 1338/100000 [00:04<06:04, 271.00it/s]\u001b[A\n",
            "  1%|▏         | 1375/100000 [00:04<05:36, 292.83it/s]\u001b[A\n",
            "  1%|▏         | 1406/100000 [00:04<05:32, 296.11it/s]\u001b[A\n",
            "  1%|▏         | 1440/100000 [00:05<05:22, 305.99it/s]\u001b[A\n",
            "  1%|▏         | 1472/100000 [00:05<05:39, 290.35it/s]\u001b[A\n",
            "  2%|▏         | 1506/100000 [00:05<05:25, 302.17it/s]\u001b[A\n",
            "  2%|▏         | 1541/100000 [00:05<05:13, 314.24it/s]\u001b[A\n",
            "  2%|▏         | 1573/100000 [00:05<05:20, 307.05it/s]\u001b[A\n",
            "  2%|▏         | 1605/100000 [00:05<05:18, 309.31it/s]\u001b[A\n",
            "  2%|▏         | 1638/100000 [00:05<05:12, 314.56it/s]\u001b[A\n",
            "  2%|▏         | 1672/100000 [00:05<05:11, 315.95it/s]\u001b[A\n",
            "  2%|▏         | 1704/100000 [00:05<05:10, 317.08it/s]\u001b[A\n",
            "  2%|▏         | 1736/100000 [00:06<05:13, 313.83it/s]\u001b[A\n",
            "  2%|▏         | 1768/100000 [00:06<05:16, 310.76it/s]\u001b[A\n",
            "  2%|▏         | 1800/100000 [00:06<05:25, 301.59it/s]\u001b[A\n",
            "  2%|▏         | 1833/100000 [00:06<05:19, 307.55it/s]\u001b[A\n",
            "  2%|▏         | 1864/100000 [00:06<05:28, 298.58it/s]\u001b[A\n",
            "  2%|▏         | 1895/100000 [00:06<05:25, 300.98it/s]\u001b[A\n",
            "  2%|▏         | 1926/100000 [00:06<05:36, 291.51it/s]\u001b[A\n",
            "  2%|▏         | 1956/100000 [00:06<05:37, 290.50it/s]\u001b[A\n",
            "  2%|▏         | 1990/100000 [00:06<05:25, 300.83it/s]\u001b[A\n",
            "  2%|▏         | 2021/100000 [00:06<05:26, 300.23it/s]\u001b[A\n",
            "  2%|▏         | 2053/100000 [00:07<05:20, 305.63it/s]\u001b[A\n",
            "  2%|▏         | 2086/100000 [00:07<05:13, 312.49it/s]\u001b[A\n",
            "  2%|▏         | 2120/100000 [00:07<05:07, 318.75it/s]\u001b[A\n",
            "  2%|▏         | 2157/100000 [00:07<04:56, 330.48it/s]\u001b[A\n",
            "  2%|▏         | 2191/100000 [00:07<05:01, 324.09it/s]\u001b[A\n",
            "  2%|▏         | 2224/100000 [00:07<05:05, 320.44it/s]\u001b[A\n",
            "  2%|▏         | 2259/100000 [00:07<04:57, 328.64it/s]\u001b[A\n",
            "  2%|▏         | 2296/100000 [00:07<04:48, 339.13it/s]\u001b[A\n",
            "  2%|▏         | 2331/100000 [00:07<05:02, 322.58it/s]\u001b[A\n",
            "  2%|▏         | 2364/100000 [00:08<05:16, 308.44it/s]\u001b[A\n",
            "  2%|▏         | 2396/100000 [00:08<05:20, 304.85it/s]\u001b[A\n",
            "  2%|▏         | 2429/100000 [00:08<05:14, 310.38it/s]\u001b[A\n",
            "  2%|▏         | 2461/100000 [00:08<05:23, 301.96it/s]\u001b[A\n",
            "  2%|▏         | 2492/100000 [00:08<05:36, 289.88it/s]\u001b[A\n",
            "  3%|▎         | 2522/100000 [00:08<05:49, 279.17it/s]\u001b[A\n",
            "  3%|▎         | 2551/100000 [00:08<05:51, 277.42it/s]\u001b[A\n",
            "  3%|▎         | 2585/100000 [00:08<05:32, 292.63it/s]\u001b[A\n",
            "  3%|▎         | 2618/100000 [00:08<05:22, 302.38it/s]\u001b[A\n",
            "  3%|▎         | 2650/100000 [00:08<05:18, 305.39it/s]\u001b[A\n",
            "  3%|▎         | 2681/100000 [00:09<05:30, 294.59it/s]\u001b[A\n",
            "  3%|▎         | 2720/100000 [00:09<05:08, 315.79it/s]\u001b[A\n",
            "  3%|▎         | 2757/100000 [00:09<04:55, 329.45it/s]\u001b[A\n",
            "  3%|▎         | 2791/100000 [00:09<05:02, 320.82it/s]\u001b[A\n",
            "  3%|▎         | 2825/100000 [00:09<04:58, 325.18it/s]\u001b[A\n",
            "  3%|▎         | 2858/100000 [00:09<05:02, 320.79it/s]\u001b[A\n",
            "  3%|▎         | 2892/100000 [00:09<04:58, 325.12it/s]\u001b[A\n",
            "  3%|▎         | 2925/100000 [00:09<05:07, 315.61it/s]\u001b[A\n",
            "  3%|▎         | 2957/100000 [00:09<05:28, 295.29it/s]\u001b[A\n",
            "  3%|▎         | 2988/100000 [00:10<05:24, 299.28it/s]\u001b[A\n",
            "  3%|▎         | 3019/100000 [00:10<05:24, 299.11it/s]\u001b[A\n",
            "  3%|▎         | 3050/100000 [00:10<05:21, 301.79it/s]\u001b[A\n",
            "  3%|▎         | 3082/100000 [00:10<05:18, 304.72it/s]\u001b[A\n",
            "  3%|▎         | 3116/100000 [00:10<05:09, 313.13it/s]\u001b[A\n",
            "  3%|▎         | 3154/100000 [00:10<04:54, 328.88it/s]\u001b[A\n",
            "  3%|▎         | 3188/100000 [00:10<04:54, 329.28it/s]\u001b[A\n",
            "  3%|▎         | 3224/100000 [00:10<04:47, 336.12it/s]\u001b[A\n",
            "  3%|▎         | 3258/100000 [00:10<04:56, 326.63it/s]\u001b[A\n",
            "  3%|▎         | 3291/100000 [00:11<05:04, 317.08it/s]\u001b[A\n",
            "  3%|▎         | 3324/100000 [00:11<05:01, 320.78it/s]\u001b[A\n",
            "  3%|▎         | 3360/100000 [00:11<04:51, 331.51it/s]\u001b[A\n",
            "  3%|▎         | 3394/100000 [00:11<04:57, 324.55it/s]\u001b[A\n",
            "  3%|▎         | 3428/100000 [00:11<04:54, 327.89it/s]\u001b[A\n",
            "  3%|▎         | 3461/100000 [00:11<04:58, 323.53it/s]\u001b[A\n",
            "  3%|▎         | 3494/100000 [00:11<05:04, 316.51it/s]\u001b[A\n",
            "  4%|▎         | 3526/100000 [00:11<05:08, 313.12it/s]\u001b[A\n",
            "  4%|▎         | 3560/100000 [00:11<05:00, 320.65it/s]\u001b[A\n",
            "  4%|▎         | 3600/100000 [00:11<04:42, 340.87it/s]\u001b[A\n",
            "  4%|▎         | 3638/100000 [00:12<04:34, 351.17it/s]\u001b[A\n",
            "  4%|▎         | 3674/100000 [00:12<04:42, 341.21it/s]\u001b[A\n",
            "  4%|▎         | 3709/100000 [00:12<04:49, 332.04it/s]\u001b[A\n",
            "  4%|▎         | 3743/100000 [00:12<05:02, 318.38it/s]\u001b[A\n",
            "  4%|▍         | 3781/100000 [00:12<04:48, 333.45it/s]\u001b[A\n",
            "  4%|▍         | 3818/100000 [00:12<04:41, 342.05it/s]\u001b[A\n",
            "  4%|▍         | 3855/100000 [00:12<04:34, 349.72it/s]\u001b[A\n",
            "  4%|▍         | 3891/100000 [00:12<04:40, 342.20it/s]\u001b[A\n",
            "  4%|▍         | 3927/100000 [00:12<04:38, 345.35it/s]\u001b[A\n",
            "  4%|▍         | 3962/100000 [00:13<04:46, 334.76it/s]\u001b[A\n",
            "  4%|▍         | 3996/100000 [00:13<04:48, 332.28it/s]\u001b[A\n",
            "  4%|▍         | 4030/100000 [00:13<04:54, 326.33it/s]\u001b[A\n",
            "  4%|▍         | 4063/100000 [00:13<04:54, 325.83it/s]\u001b[A\n",
            "  4%|▍         | 4096/100000 [00:13<05:02, 316.83it/s]\u001b[A\n",
            "  4%|▍         | 4129/100000 [00:13<04:59, 320.32it/s]\u001b[A\n",
            "  4%|▍         | 4162/100000 [00:13<04:58, 320.53it/s]\u001b[A\n",
            "  4%|▍         | 4195/100000 [00:13<05:12, 306.41it/s]\u001b[A\n",
            "  4%|▍         | 4226/100000 [00:13<05:16, 302.43it/s]\u001b[A\n",
            "  4%|▍         | 4257/100000 [00:13<05:14, 304.38it/s]\u001b[A\n",
            "  4%|▍         | 4288/100000 [00:14<05:14, 304.78it/s]\u001b[A\n",
            "  4%|▍         | 4321/100000 [00:14<05:08, 310.56it/s]\u001b[A\n",
            "  4%|▍         | 4353/100000 [00:14<05:16, 302.24it/s]\u001b[A\n",
            "  4%|▍         | 4387/100000 [00:14<05:07, 311.17it/s]\u001b[A\n",
            "  4%|▍         | 4422/100000 [00:14<04:58, 319.95it/s]\u001b[A\n",
            "  4%|▍         | 4455/100000 [00:14<05:02, 315.86it/s]\u001b[A\n",
            "  4%|▍         | 4487/100000 [00:14<05:03, 314.78it/s]\u001b[A\n",
            "  5%|▍         | 4524/100000 [00:14<04:50, 328.30it/s]\u001b[A\n",
            "  5%|▍         | 4560/100000 [00:14<04:46, 333.42it/s]\u001b[A\n",
            "  5%|▍         | 4597/100000 [00:14<04:38, 342.83it/s]\u001b[A\n",
            "  5%|▍         | 4632/100000 [00:15<04:39, 341.46it/s]\u001b[A\n",
            "  5%|▍         | 4667/100000 [00:15<04:47, 331.55it/s]\u001b[A\n",
            "  5%|▍         | 4705/100000 [00:15<04:38, 342.63it/s]\u001b[A\n",
            "  5%|▍         | 4740/100000 [00:15<04:55, 322.03it/s]\u001b[A\n",
            "  5%|▍         | 4773/100000 [00:15<05:02, 315.26it/s]\u001b[A\n",
            "  5%|▍         | 4807/100000 [00:15<04:55, 321.83it/s]\u001b[A\n",
            "  5%|▍         | 4840/100000 [00:15<04:59, 317.97it/s]\u001b[A\n",
            "  5%|▍         | 4875/100000 [00:15<04:51, 326.25it/s]\u001b[A\n",
            "  5%|▍         | 4908/100000 [00:15<04:53, 324.06it/s]\u001b[A\n",
            "  5%|▍         | 4944/100000 [00:16<04:46, 331.54it/s]\u001b[A\n",
            "  5%|▍         | 4980/100000 [00:16<04:41, 337.29it/s]\u001b[A\n",
            "  5%|▌         | 5014/100000 [00:16<04:51, 326.29it/s]\u001b[A\n",
            "  5%|▌         | 5049/100000 [00:16<04:46, 331.38it/s]\u001b[A\n",
            "  5%|▌         | 5083/100000 [00:16<04:50, 326.77it/s]\u001b[A\n",
            "  5%|▌         | 5118/100000 [00:16<04:46, 331.64it/s]\u001b[A\n",
            "  5%|▌         | 5156/100000 [00:16<04:35, 344.73it/s]\u001b[A\n",
            "  5%|▌         | 5191/100000 [00:16<04:43, 334.12it/s]\u001b[A\n",
            "  5%|▌         | 5229/100000 [00:16<04:34, 345.06it/s]\u001b[A\n",
            "  5%|▌         | 5264/100000 [00:17<04:37, 341.25it/s]\u001b[A\n",
            "  5%|▌         | 5299/100000 [00:17<04:44, 332.35it/s]\u001b[A\n",
            "  5%|▌         | 5333/100000 [00:17<04:46, 329.91it/s]\u001b[A\n",
            "  5%|▌         | 5367/100000 [00:17<04:51, 324.76it/s]\u001b[A\n",
            "  5%|▌         | 5401/100000 [00:17<04:48, 328.36it/s]\u001b[A\n",
            "  5%|▌         | 5438/100000 [00:17<04:38, 339.09it/s]\u001b[A\n",
            "  5%|▌         | 5473/100000 [00:17<04:37, 340.29it/s]\u001b[A\n",
            "  6%|▌         | 5508/100000 [00:17<04:42, 334.31it/s]\u001b[A\n",
            "  6%|▌         | 5542/100000 [00:17<04:57, 317.39it/s]\u001b[A\n",
            "  6%|▌         | 5576/100000 [00:17<04:52, 322.92it/s]\u001b[A\n",
            "  6%|▌         | 5609/100000 [00:18<04:51, 323.66it/s]\u001b[A\n",
            "  6%|▌         | 5643/100000 [00:18<04:47, 328.13it/s]\u001b[A\n",
            "  6%|▌         | 5676/100000 [00:18<04:55, 319.65it/s]\u001b[A\n",
            "  6%|▌         | 5709/100000 [00:18<04:52, 322.48it/s]\u001b[A\n",
            "  6%|▌         | 5742/100000 [00:18<04:57, 317.09it/s]\u001b[A\n",
            "  6%|▌         | 5782/100000 [00:18<04:40, 336.29it/s]\u001b[A\n",
            "  6%|▌         | 5817/100000 [00:18<04:37, 339.85it/s]\u001b[A\n",
            "  6%|▌         | 5854/100000 [00:18<04:31, 346.36it/s]\u001b[A\n",
            "  6%|▌         | 5889/100000 [00:18<04:34, 342.34it/s]\u001b[A\n",
            "  6%|▌         | 5924/100000 [00:19<04:36, 340.62it/s]\u001b[A\n",
            "  6%|▌         | 5959/100000 [00:19<04:51, 322.15it/s]\u001b[A\n",
            "  6%|▌         | 5992/100000 [00:19<04:51, 322.37it/s]\u001b[A\n",
            "  6%|▌         | 6025/100000 [00:19<04:56, 316.84it/s]\u001b[A\n",
            "  6%|▌         | 6057/100000 [00:19<05:01, 311.50it/s]\u001b[A\n",
            "  6%|▌         | 6094/100000 [00:19<04:47, 326.07it/s]\u001b[A\n",
            "  6%|▌         | 6127/100000 [00:19<04:48, 325.75it/s]\u001b[A\n",
            "  6%|▌         | 6160/100000 [00:19<04:48, 325.42it/s]\u001b[A\n",
            "  6%|▌         | 6197/100000 [00:19<04:39, 335.34it/s]\u001b[A\n",
            "  6%|▌         | 6231/100000 [00:19<04:44, 329.62it/s]\u001b[A\n",
            "  6%|▋         | 6265/100000 [00:20<04:44, 329.38it/s]\u001b[A\n",
            "  6%|▋         | 6300/100000 [00:20<04:39, 335.01it/s]\u001b[A\n",
            "  6%|▋         | 6334/100000 [00:20<04:39, 335.48it/s]\u001b[A\n",
            "  6%|▋         | 6374/100000 [00:20<04:27, 350.22it/s]\u001b[A\n",
            "  6%|▋         | 6411/100000 [00:20<04:24, 353.98it/s]\u001b[A\n",
            "  6%|▋         | 6447/100000 [00:20<04:26, 350.81it/s]\u001b[A\n",
            "  6%|▋         | 6483/100000 [00:20<04:26, 351.30it/s]\u001b[A\n",
            "  7%|▋         | 6519/100000 [00:20<04:31, 344.79it/s]\u001b[A\n",
            "  7%|▋         | 6556/100000 [00:20<04:25, 351.50it/s]\u001b[A\n",
            "  7%|▋         | 6592/100000 [00:21<04:58, 313.17it/s]\u001b[A\n",
            "  7%|▋         | 6625/100000 [00:21<04:56, 314.56it/s]\u001b[A\n",
            "  7%|▋         | 6658/100000 [00:21<04:53, 317.83it/s]\u001b[A\n",
            "  7%|▋         | 6691/100000 [00:21<04:57, 313.94it/s]\u001b[A\n",
            "  7%|▋         | 6723/100000 [00:21<05:12, 298.86it/s]\u001b[A\n",
            "  7%|▋         | 6754/100000 [00:21<05:11, 299.08it/s]\u001b[A\n",
            "  7%|▋         | 6785/100000 [00:21<05:13, 297.07it/s]\u001b[A\n",
            "  7%|▋         | 6815/100000 [00:21<05:12, 297.82it/s]\u001b[A\n",
            "  7%|▋         | 6846/100000 [00:21<05:09, 300.73it/s]\u001b[A\n",
            "  7%|▋         | 6879/100000 [00:21<05:05, 305.17it/s]\u001b[A\n",
            "  7%|▋         | 6913/100000 [00:22<04:56, 313.46it/s]\u001b[A\n",
            "  7%|▋         | 6949/100000 [00:22<04:47, 323.91it/s]\u001b[A\n",
            "  7%|▋         | 6982/100000 [00:22<04:55, 314.90it/s]\u001b[A\n",
            "  7%|▋         | 7014/100000 [00:22<04:56, 313.45it/s]\u001b[A\n",
            "  7%|▋         | 7048/100000 [00:22<04:52, 317.33it/s]\u001b[A\n",
            "  7%|▋         | 7080/100000 [00:22<04:58, 311.54it/s]\u001b[A\n",
            "  7%|▋         | 7115/100000 [00:22<04:49, 320.77it/s]\u001b[A\n",
            "  7%|▋         | 7150/100000 [00:22<04:44, 326.68it/s]\u001b[A\n",
            "  7%|▋         | 7183/100000 [00:22<04:43, 327.33it/s]\u001b[A\n",
            "  7%|▋         | 7216/100000 [00:23<04:43, 327.06it/s]\u001b[A\n",
            "  7%|▋         | 7249/100000 [00:23<04:44, 326.53it/s]\u001b[A\n",
            "  7%|▋         | 7282/100000 [00:23<04:50, 319.40it/s]\u001b[A\n",
            "  7%|▋         | 7317/100000 [00:23<04:43, 327.09it/s]\u001b[A\n",
            "  7%|▋         | 7352/100000 [00:23<04:38, 332.82it/s]\u001b[A\n",
            "  7%|▋         | 7389/100000 [00:23<04:33, 339.21it/s]\u001b[A\n",
            "  7%|▋         | 7424/100000 [00:23<04:43, 326.96it/s]\u001b[A\n",
            "  7%|▋         | 7457/100000 [00:23<04:55, 313.24it/s]\u001b[A\n",
            "  7%|▋         | 7495/100000 [00:23<04:40, 330.36it/s]\u001b[A\n",
            "  8%|▊         | 7531/100000 [00:23<04:33, 337.85it/s]\u001b[A\n",
            "  8%|▊         | 7566/100000 [00:24<04:38, 331.92it/s]\u001b[A\n",
            "  8%|▊         | 7602/100000 [00:24<04:34, 336.01it/s]\u001b[A\n",
            "  8%|▊         | 7638/100000 [00:24<04:29, 342.32it/s]\u001b[A\n",
            "  8%|▊         | 7676/100000 [00:24<04:23, 350.31it/s]\u001b[A\n",
            "  8%|▊         | 7712/100000 [00:24<04:28, 343.19it/s]\u001b[A\n",
            "  8%|▊         | 7747/100000 [00:24<04:28, 344.14it/s]\u001b[A\n",
            "  8%|▊         | 7784/100000 [00:24<04:22, 350.69it/s]\u001b[A\n",
            "  8%|▊         | 7820/100000 [00:24<04:31, 340.10it/s]\u001b[A\n",
            "  8%|▊         | 7855/100000 [00:24<04:29, 342.36it/s]\u001b[A\n",
            "  8%|▊         | 7891/100000 [00:25<04:28, 343.61it/s]\u001b[A\n",
            "  8%|▊         | 7928/100000 [00:25<04:22, 350.71it/s]\u001b[A\n",
            "  8%|▊         | 7965/100000 [00:25<04:20, 353.57it/s]\u001b[A\n",
            "  8%|▊         | 8001/100000 [00:25<04:21, 352.04it/s]\u001b[A\n",
            "  8%|▊         | 8039/100000 [00:25<04:15, 359.25it/s]\u001b[A\n",
            "  8%|▊         | 8075/100000 [00:25<04:16, 357.86it/s]\u001b[A\n",
            "  8%|▊         | 8111/100000 [00:25<04:21, 351.94it/s]\u001b[A\n",
            "  8%|▊         | 8149/100000 [00:25<04:16, 358.35it/s]\u001b[A\n",
            "  8%|▊         | 8187/100000 [00:25<04:13, 362.17it/s]\u001b[A\n",
            "  8%|▊         | 8224/100000 [00:25<04:18, 355.38it/s]\u001b[A\n",
            "  8%|▊         | 8260/100000 [00:26<04:21, 351.48it/s]\u001b[A\n",
            "  8%|▊         | 8296/100000 [00:26<04:26, 344.52it/s]\u001b[A\n",
            "  8%|▊         | 8331/100000 [00:26<04:34, 334.30it/s]\u001b[A\n",
            "  8%|▊         | 8368/100000 [00:26<04:27, 342.73it/s]\u001b[A\n",
            "  8%|▊         | 8403/100000 [00:26<04:35, 332.07it/s]\u001b[A\n",
            "  8%|▊         | 8440/100000 [00:26<04:28, 340.69it/s]\u001b[A\n",
            "  8%|▊         | 8479/100000 [00:26<04:18, 353.79it/s]\u001b[A\n",
            "  9%|▊         | 8515/100000 [00:26<04:21, 350.23it/s]\u001b[A\n",
            "  9%|▊         | 8551/100000 [00:26<04:22, 348.99it/s]\u001b[A\n",
            "  9%|▊         | 8587/100000 [00:26<04:21, 350.13it/s]\u001b[A\n",
            "  9%|▊         | 8623/100000 [00:27<04:27, 341.84it/s]\u001b[A\n",
            "  9%|▊         | 8658/100000 [00:27<04:30, 337.34it/s]\u001b[A\n",
            "  9%|▊         | 8692/100000 [00:27<04:44, 320.74it/s]\u001b[A\n",
            "  9%|▊         | 8727/100000 [00:27<04:38, 328.30it/s]\u001b[A\n",
            "  9%|▉         | 8762/100000 [00:27<04:34, 332.13it/s]\u001b[A\n",
            "  9%|▉         | 8796/100000 [00:27<04:43, 321.57it/s]\u001b[A\n",
            "  9%|▉         | 8829/100000 [00:27<04:47, 317.37it/s]\u001b[A\n",
            "  9%|▉         | 8861/100000 [00:27<04:53, 310.26it/s]\u001b[A\n",
            "  9%|▉         | 8893/100000 [00:27<04:53, 310.21it/s]\u001b[A\n",
            "  9%|▉         | 8926/100000 [00:28<04:49, 314.83it/s]\u001b[A\n",
            "  9%|▉         | 8958/100000 [00:28<04:53, 310.21it/s]\u001b[A\n",
            "  9%|▉         | 8990/100000 [00:28<04:56, 306.69it/s]\u001b[A\n",
            "  9%|▉         | 9026/100000 [00:28<04:45, 318.99it/s]\u001b[A\n",
            "  9%|▉         | 9059/100000 [00:28<04:46, 317.77it/s]\u001b[A\n",
            "  9%|▉         | 9094/100000 [00:28<04:38, 326.28it/s]\u001b[A\n",
            "  9%|▉         | 9131/100000 [00:28<04:30, 335.54it/s]\u001b[A\n",
            "  9%|▉         | 9165/100000 [00:28<04:30, 336.25it/s]\u001b[A\n",
            "  9%|▉         | 9201/100000 [00:28<04:25, 342.10it/s]\u001b[A\n",
            "  9%|▉         | 9236/100000 [00:28<04:26, 340.81it/s]\u001b[A\n",
            "  9%|▉         | 9271/100000 [00:29<04:29, 336.96it/s]\u001b[A\n",
            "  9%|▉         | 9306/100000 [00:29<04:26, 339.91it/s]\u001b[A\n",
            "  9%|▉         | 9341/100000 [00:29<04:34, 330.52it/s]\u001b[A\n",
            "  9%|▉         | 9376/100000 [00:29<04:30, 335.25it/s]\u001b[A\n",
            "  9%|▉         | 9412/100000 [00:29<04:25, 341.64it/s]\u001b[A\n",
            "  9%|▉         | 9447/100000 [00:29<04:30, 334.42it/s]\u001b[A\n",
            "  9%|▉         | 9481/100000 [00:29<04:40, 322.28it/s]\u001b[A\n",
            " 10%|▉         | 9514/100000 [00:29<04:40, 322.15it/s]\u001b[A\n",
            " 10%|▉         | 9547/100000 [00:29<04:41, 320.96it/s]\u001b[A\n",
            " 10%|▉         | 9580/100000 [00:30<04:44, 318.03it/s]\u001b[A\n",
            " 10%|▉         | 9615/100000 [00:30<04:37, 326.02it/s]\u001b[A\n",
            " 10%|▉         | 9652/100000 [00:30<04:29, 335.01it/s]\u001b[A\n",
            " 10%|▉         | 9688/100000 [00:30<04:24, 341.15it/s]\u001b[A\n",
            " 10%|▉         | 9724/100000 [00:30<04:20, 346.03it/s]\u001b[A\n",
            " 10%|▉         | 9759/100000 [00:30<04:20, 346.41it/s]\u001b[A\n",
            " 10%|▉         | 9794/100000 [00:30<04:27, 336.78it/s]\u001b[A\n",
            " 10%|▉         | 9828/100000 [00:30<04:34, 328.74it/s]\u001b[A\n",
            " 10%|▉         | 9866/100000 [00:30<04:23, 341.86it/s]\u001b[A\n",
            " 10%|▉         | 9904/100000 [00:30<04:16, 350.88it/s]\u001b[A\n",
            " 10%|▉         | 9940/100000 [00:31<04:30, 332.82it/s]\u001b[A\n",
            " 10%|▉         | 9974/100000 [00:31<04:32, 330.63it/s]\u001b[A\n",
            " 10%|█         | 10008/100000 [00:31<04:35, 327.17it/s]\u001b[A\n",
            " 10%|█         | 10045/100000 [00:31<04:26, 337.20it/s]\u001b[A\n",
            " 10%|█         | 10079/100000 [00:31<04:31, 330.84it/s]\u001b[A\n",
            " 10%|█         | 10113/100000 [00:31<04:36, 325.42it/s]\u001b[A\n",
            " 10%|█         | 10149/100000 [00:31<04:31, 330.55it/s]\u001b[A\n",
            " 10%|█         | 10183/100000 [00:31<04:42, 318.29it/s]\u001b[A\n",
            " 10%|█         | 10220/100000 [00:31<04:31, 331.15it/s]\u001b[A\n",
            " 10%|█         | 10258/100000 [00:32<04:21, 342.86it/s]\u001b[A\n",
            " 10%|█         | 10296/100000 [00:32<04:15, 350.48it/s]\u001b[A\n",
            " 10%|█         | 10332/100000 [00:32<04:26, 337.03it/s]\u001b[A\n",
            " 10%|█         | 10366/100000 [00:32<04:30, 331.80it/s]\u001b[A\n",
            " 10%|█         | 10401/100000 [00:32<04:26, 336.67it/s]\u001b[A\n",
            " 10%|█         | 10440/100000 [00:32<04:16, 348.81it/s]\u001b[A\n",
            " 10%|█         | 10476/100000 [00:32<04:19, 345.59it/s]\u001b[A\n",
            " 11%|█         | 10511/100000 [00:32<04:30, 331.42it/s]\u001b[A\n",
            " 11%|█         | 10548/100000 [00:32<04:23, 340.06it/s]\u001b[A\n",
            " 11%|█         | 10583/100000 [00:33<04:28, 333.20it/s]\u001b[A\n",
            " 11%|█         | 10617/100000 [00:33<04:33, 326.34it/s]\u001b[A\n",
            " 11%|█         | 10650/100000 [00:33<04:45, 313.42it/s]\u001b[A\n",
            " 11%|█         | 10685/100000 [00:33<04:36, 323.46it/s]\u001b[A\n",
            " 11%|█         | 10718/100000 [00:33<04:35, 323.94it/s]\u001b[A\n",
            " 11%|█         | 10752/100000 [00:33<04:32, 327.68it/s]\u001b[A\n",
            " 11%|█         | 10793/100000 [00:33<04:18, 345.43it/s]\u001b[A\n",
            " 11%|█         | 10828/100000 [00:33<04:24, 337.00it/s]\u001b[A\n",
            " 11%|█         | 10862/100000 [00:33<04:30, 329.40it/s]\u001b[A\n",
            " 11%|█         | 10896/100000 [00:33<04:34, 324.50it/s]\u001b[A\n",
            " 11%|█         | 10933/100000 [00:34<04:27, 333.36it/s]\u001b[A\n",
            " 11%|█         | 10969/100000 [00:34<04:21, 340.60it/s]\u001b[A\n",
            " 11%|█         | 11004/100000 [00:34<04:26, 333.87it/s]\u001b[A\n",
            " 11%|█         | 11038/100000 [00:34<04:35, 323.24it/s]\u001b[A\n",
            " 11%|█         | 11071/100000 [00:34<04:34, 324.36it/s]\u001b[A\n",
            " 11%|█         | 11104/100000 [00:34<04:40, 316.46it/s]\u001b[A\n",
            " 11%|█         | 11140/100000 [00:34<04:31, 327.45it/s]\u001b[A\n",
            " 11%|█         | 11173/100000 [00:34<04:32, 325.71it/s]\u001b[A\n",
            " 11%|█         | 11208/100000 [00:34<04:27, 331.61it/s]\u001b[A\n",
            " 11%|█         | 11242/100000 [00:35<04:33, 324.47it/s]\u001b[A\n",
            " 11%|█▏        | 11275/100000 [00:35<04:33, 324.69it/s]\u001b[A\n",
            " 11%|█▏        | 11309/100000 [00:35<04:30, 328.37it/s]\u001b[A\n",
            " 11%|█▏        | 11342/100000 [00:35<04:30, 327.57it/s]\u001b[A\n",
            " 11%|█▏        | 11378/100000 [00:35<04:23, 336.03it/s]\u001b[A\n",
            " 11%|█▏        | 11412/100000 [00:35<04:26, 332.87it/s]\u001b[A\n",
            " 11%|█▏        | 11447/100000 [00:35<04:24, 335.28it/s]\u001b[A\n",
            " 11%|█▏        | 11485/100000 [00:35<04:16, 344.95it/s]\u001b[A\n",
            " 12%|█▏        | 11522/100000 [00:35<04:11, 351.65it/s]\u001b[A\n",
            " 12%|█▏        | 11558/100000 [00:35<04:24, 334.75it/s]\u001b[A\n",
            " 12%|█▏        | 11592/100000 [00:36<04:24, 334.32it/s]\u001b[A\n",
            " 12%|█▏        | 11626/100000 [00:36<04:26, 331.86it/s]\u001b[A\n",
            " 12%|█▏        | 11660/100000 [00:36<04:39, 316.25it/s]\u001b[A\n",
            " 12%|█▏        | 11692/100000 [00:36<04:43, 311.58it/s]\u001b[A\n",
            " 12%|█▏        | 11724/100000 [00:36<04:49, 305.02it/s]\u001b[A\n",
            " 12%|█▏        | 11756/100000 [00:36<04:48, 306.08it/s]\u001b[A\n",
            " 12%|█▏        | 11791/100000 [00:36<04:39, 316.11it/s]\u001b[A\n",
            " 12%|█▏        | 11823/100000 [00:36<04:40, 314.28it/s]\u001b[A\n",
            " 12%|█▏        | 11859/100000 [00:36<04:30, 326.39it/s]\u001b[A\n",
            " 12%|█▏        | 11896/100000 [00:37<04:21, 337.29it/s]\u001b[A\n",
            " 12%|█▏        | 11936/100000 [00:37<04:10, 351.65it/s]\u001b[A\n",
            " 12%|█▏        | 11975/100000 [00:37<04:04, 360.57it/s]\u001b[A\n",
            " 12%|█▏        | 12012/100000 [00:37<04:09, 352.88it/s]\u001b[A\n",
            " 12%|█▏        | 12048/100000 [00:37<04:27, 328.27it/s]\u001b[A\n",
            " 12%|█▏        | 12086/100000 [00:37<04:17, 341.47it/s]\u001b[A\n",
            " 12%|█▏        | 12121/100000 [00:37<04:18, 339.59it/s]\u001b[A\n",
            " 12%|█▏        | 12157/100000 [00:37<04:15, 343.74it/s]\u001b[A\n",
            " 12%|█▏        | 12192/100000 [00:37<04:25, 330.31it/s]\u001b[A\n",
            " 12%|█▏        | 12226/100000 [00:37<04:30, 324.39it/s]\u001b[A\n",
            " 12%|█▏        | 12260/100000 [00:38<04:27, 327.93it/s]\u001b[A\n",
            " 12%|█▏        | 12294/100000 [00:38<04:24, 331.31it/s]\u001b[A\n",
            " 12%|█▏        | 12328/100000 [00:38<04:25, 330.06it/s]\u001b[A\n",
            " 12%|█▏        | 12362/100000 [00:38<04:36, 317.44it/s]\u001b[A\n",
            " 12%|█▏        | 12394/100000 [00:38<04:41, 311.33it/s]\u001b[A\n",
            " 12%|█▏        | 12427/100000 [00:38<04:38, 313.93it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-aa9703f827a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Do lemmatization keeping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdata_lemmatized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_words_nostops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_lemmatized ok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a29c21149410>\u001b[0m in \u001b[0;36mlemmatization\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtexts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtexts_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.predict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seqs_in)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mops.pyx\u001b[0m in \u001b[0;36mthinc.neural.ops.Ops.flatten\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihhUsP-RRwxi"
      },
      "source": [
        "##### Recuperation du CSV propre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8IXDkYMRzfI"
      },
      "source": [
        "### enrigetrement du body nottoyé dans un fichier csv\n",
        "df = pd.DataFrame()\n",
        "df['body'] = col\n",
        "df.to_csv(\"/content/drive/MyDrive/kaggle Project/Données/clean_body.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UGuI94o1uTX"
      },
      "source": [
        "# recharement du col_body depuis clean_body.csv \n",
        "col_body = pd.read_csv(\"/content/drive/MyDrive/kaggle Project/Données/Data_Feature/clean_body.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9E0PVyC1zXd"
      },
      "source": [
        "### nettoyage du col body afin de l'exmploiter\n",
        "for j in tqdm(range(len(col_body))):\n",
        "    for i in ['[', ']', \"'\", \" \"]:\n",
        "        col_body[j] = col_body[j].replace(i, \"\")\n",
        "    col_body[j] = col_body[j].split(\",\")\n",
        "\n",
        "col_body = col_body.to_list()\n",
        "\n",
        "del j, i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ydL4ap5cPXs"
      },
      "source": [
        "##### creation des topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMej_kgl12M-"
      },
      "source": [
        "# Creation d'un dictionnaire de tous les mots du col body ()\n",
        "id2word = corpora.Dictionary(col_body)\n",
        "print(\"dict ok\")\n",
        "\n",
        "# creaction du corpus (texts) \n",
        "texts = col_body\n",
        "print(\"text ok\")\n",
        "\n",
        "# vectorisation de nos mots \n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(\"corpus ok\")\n",
        "\n",
        "del col_body, texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65zWP9wgc9Be"
      },
      "source": [
        "limit = 20\n",
        "start = 2\n",
        "step = 2\n",
        "\n",
        "for num_topics in tqdm(range(start, limit, step)):\n",
        "    lda_model = gensim.models.LdaModel(corpus,\n",
        "                                       num_topics=num_topics,\n",
        "                                       id2word=id2word,\n",
        "                                       random_state=100,\n",
        "                                       alpha='auto')\n",
        "\n",
        "    coherencemodel = CoherenceModel(\n",
        "        model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
        "    print(\"coherence avec \", num_topics, \" topics : \",\n",
        "          coherencemodel.get_coherence())\n",
        "\n",
        "\n",
        "del limit, start, step, coherencemodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td-gGteUsyAf"
      },
      "source": [
        "on prendra 12 topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXjHUlix19yb"
      },
      "source": [
        "## entrainement d'un modele qui va nous permettre de clusteriser nos \n",
        "## commentaires par topics\n",
        "lda_model = gensim.models.LdaModel(corpus,\n",
        "                                   num_topics=12,\n",
        "                                   id2word=id2word,\n",
        "                                   random_state=100,\n",
        "                                   alpha='auto')\n",
        "\n",
        "del id2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOXD8d7z1_d_"
      },
      "source": [
        "def format_topics_sentences(ldamodel, corpus):\n",
        "    \"\"\"\"Documentation\n",
        "      Parameters:\n",
        "            ldamodel : notre modele entrainé pour clusteriser nos commentaire par topic\n",
        "            corpus : tous nos commentaires\n",
        "      Out :\n",
        "            chaque commentaire est associé à son topic (creation d'une column dans notre df)\n",
        "\n",
        "    \"\"\"\n",
        "    # Iinitialisation de notre output df\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # recupere le topic qui maximise le score pour chaque commentaire\n",
        "    nb_comm = len(corpus)\n",
        "    list_topic = [int(sorted(lda_model[corpus][i], key=lambda x: (\n",
        "        x[1]), reverse=True)[0][0]) for i in tqdm(range(nb_comm))]\n",
        "    sent_topics_df['Dominant_Topic'] = list_topic\n",
        "\n",
        "    return(sent_topics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8aO6sSi2BIm"
      },
      "source": [
        "df_topic_sents_keywords = format_topics_sentences(\n",
        "    ldamodel=lda_model, corpus=corpus)\n",
        "del lda_model\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "\n",
        "del df_topic_sents_keywords\n",
        "\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic']\n",
        "\n",
        "print(\"topic / comm ok\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHEdm1uY2DaW"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['Topic'] = df_dominant_topic['Dominant_Topic']\n",
        "## enrigestrement de notre premiere feature dans un dossier csv\n",
        "df.to_csv(feature_dossier + \"topic.csv\")\n",
        "\n",
        "del df_dominant_topic, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcK8tzlMfjl4"
      },
      "source": [
        "#### 6e feature ( sentiments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8XtkV7E2FBV"
      },
      "source": [
        "col_polarity : list = []\n",
        "col_subjectivity : list= []\n",
        "chunksize : int = 10 ** 5\n",
        "\n",
        "for i, chunk in enumerate(pd.read_csv(comments_students, chunksize=chunksize)):\n",
        "    print(\"chunk \", i, \" begin\")\n",
        "    for j in chunk['body']:\n",
        "        polarity, subjectivity = TextBlob(str(j)).sentiment\n",
        "\n",
        "        col_polarity.append(polarity)\n",
        "        col_subjectivity.append(subjectivity)\n",
        "    print(\"chunk \", i, \" ok \\n\")\n",
        "\n",
        "del i, chunk, chunksize, polarity, subjectivity\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['polarity'] = col_polarity\n",
        "df['subjectivity'] = col_subjectivity\n",
        "df.to_csv(feature_dossier + \"sentiment_feature.csv\")\n",
        "\n",
        "del df, col_polarity, col_subjectivity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy3GgkOYfvOc"
      },
      "source": [
        "#### 7e feature (nb de mots body)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvkPOjCB2IA8"
      },
      "source": [
        "df = pd.DataFrame(pd.read_csv(comments_students)['body'])\n",
        "df = pd.concat([df, pd.DataFrame([len(str(x).split(' '))\n",
        "                                  for x in df['body']], columns=['nb_mot_body'])], axis=1)\n",
        "df = df.drop('body', axis=1)\n",
        "\n",
        "df.to_csv(feature_dossier + \"nb_mot_body.csv\")\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ6mF7_jf4wl"
      },
      "source": [
        "#### 8e feature(post_comm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eumBUWKL2KQM"
      },
      "source": [
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv(comments_students)[['name', 'link_id']]\n",
        "\n",
        "# Ajout du post ( <=> t3) correspondant au commentaire\n",
        "link_new_id = {df['link_id'][i]: i for i in tqdm(range(len(df)))}\n",
        "df['link_new_id'] = [link_new_id[i] for i in df['link_id'].values]\n",
        "df = pd.DataFrame(df['link_new_id'])\n",
        "\n",
        "# Exportation de features\n",
        "df.to_csv(feature_dossier + \"post_comm.csv\")\n",
        "del df, link_new_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yXzaAEVgEVs"
      },
      "source": [
        "#### 9e feature (pop_post)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARzUxJMA2WiM"
      },
      "source": [
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv(comments_students)[['link_id']]\n",
        "\n",
        "# Ajout de la popularité du post ( <=> nombre de commetaires dans le post = t3)\n",
        "df['pop'] = [1 for i in range(len(df))]\n",
        "df['Unnamed: 0'] = df.index\n",
        "df = pd.DataFrame(df.merge(df[['link_id', 'pop']].groupby(['link_id']).sum(), on='link_id', suffixes=(\n",
        "    '', '_post'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0']).drop(columns=['pop'])['pop_post'])\n",
        "\n",
        "df = pd.DataFrame(df['pop_post'])\n",
        "\n",
        "# Exportation de features\n",
        "df.to_csv(feature_dossier + \"pop_post.csv\")\n",
        "\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzMg3j1cgKqH"
      },
      "source": [
        "#### 10e feature (time )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgbrNTWU2faG"
      },
      "source": [
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv(comments_students)[\n",
        "    ['created_utc', 'link_id', 'author', 'name', 'parent_id']]\n",
        "\n",
        "# Ajout du temps de réponse depuis la création du post ( <=> 1er commentaire sur le post)\n",
        "df['Unnamed: 0'] = df.index\n",
        "df = df.merge(df[['link_id', 'created_utc']].groupby('link_id').min(), on='link_id', suffixes=(\n",
        "    '', '_min'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "df['time_1st_comment_post'] = df['created_utc']-df['created_utc_min']\n",
        "df = df.drop(columns=['created_utc_min'])\n",
        "\n",
        "# Ajout du temps de réponse depuis 1er post de l'auteur\n",
        "df['Unnamed: 0'] = df.index\n",
        "df = df.merge(df[['author', 'created_utc']].groupby('author').min(), on='author', suffixes=(\n",
        "    '', '_aut'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "df['time_1st_comment_author'] = df['created_utc']-df['created_utc_aut']\n",
        "\n",
        "# Ajout du temps de réponse au commentaire père\n",
        "df['Unnamed: 0'] = df.index\n",
        "df = df.merge(df[['name', 'created_utc']], left_on='parent_id', right_on='name', suffixes=(\n",
        "    '', '_parent'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "df['time_answer'] = (df['created_utc']-df['created_utc_parent']).fillna(0)\n",
        "\n",
        "# On ne garde que les colonnes des features\n",
        "df = df[['time_1st_comment_post', 'time_1st_comment_author', 'time_answer']]\n",
        "\n",
        "# Exportation de features\n",
        "df.to_csv(feature_dossier + \"time_feature.csv\")\n",
        "\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0KCgLvwgSsS"
      },
      "source": [
        "#### 11e feature (nb comm par auteur)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizB6XER2ucD"
      },
      "source": [
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv(comments_students)[['author']]\n",
        "\n",
        "# Ajout de du nombre de commentaires par autheur\n",
        "df['Unnamed: 0'] = df.index\n",
        "df['nb_com'] = [1 for i in range(len(df))]\n",
        "df = df.merge(df[['author', 'nb_com']].groupby('author').count(), on='author', suffixes=(\n",
        "    '', '_aut'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "df = pd.DataFrame(df['nb_com_aut'])\n",
        "\n",
        "# Exportation de features\n",
        "df.to_csv(feature_dossier + \"nb_comm_per_author.csv\")\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95W6dCXdJCkC"
      },
      "source": [
        "#### 12e- 13e- 14e features (nombreDescendants, nombreEnfants, ratioEnfantsDescendants)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gFJrJ9nJB84",
        "outputId": "48db66b9-8be9-42a5-b8a4-ad13196bd9f3"
      },
      "source": [
        "df=pd.read_csv(comments_students)\n",
        "G = nx.DiGraph()\n",
        "\n",
        "G.add_nodes_from(list(df['name']))\n",
        "\n",
        "\n",
        "for i in tqdm(range(df.shape[0])) :\n",
        "    \n",
        "    G.add_edge(df['parent_id'].iloc[i],df['name'].iloc[i])\n",
        "nodesPeres = list(df['parent_id'])\n",
        "nodesFils = list(df['name'])\n",
        "nombreEnfants = [len(list(G.successors(i))) for i in (df['name'])]\n",
        "nombreDescendants = [len(list(nx.nodes(nx.dfs_tree(G, i)))) for i in ( df['name']) ]\n",
        "df['nombreEnfants'] = nombreEnfants\n",
        "df['nombreDescendants'] = nombreDescendants\n",
        "df['ratioEnfantsDescendants'] = df['nombreEnfants']/df['nombreDescendants']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4234970/4234970 [02:06<00:00, 33528.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap5VPTC-JkSo"
      },
      "source": [
        "# Exportation de features\n",
        "df.to_csv(feature_dossier + \"nombreDescendants.csv\")\n",
        "df.to_csv(feature_dossier + \"nombreEnfants.csv\")\n",
        "df.to_csv(feature_dossier + \"ratioEnfantsDescendants.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeM-CmDqmEGC"
      },
      "source": [
        "#### 15e feature (mean_mod_author)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-zDBNi-mHb_"
      },
      "source": [
        "# Chargement et séparation des comments\n",
        "df = pd.read_csv(comments_students)\n",
        "train = df[~np.isnan(df['ups'])][['ups', 'author', 'parent_id']]\n",
        "test = df[np.isnan(df['ups'])][['ups', 'author', 'parent_id']]\n",
        "del df\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------\n",
        "# Partie train\n",
        "# Ajout moyenne ups author\n",
        "train['Unnamed: 0'] = train.index\n",
        "train = pd.DataFrame(train.merge(train[['ups', 'author']].groupby(['author']).mean(\n",
        "), on='author', suffixes=('', '_mean_author')).sort_values(['Unnamed: 0']).set_index(['Unnamed: 0']))\n",
        "\n",
        "\n",
        "# Ajout mode ups author\n",
        "train['Unnamed: 0'] = train.index\n",
        "temp = train[['author', 'ups']].groupby(['author'])['ups'].agg(pd.Series.mode)\n",
        "for i in temp.index:\n",
        "    if isinstance(temp[i], np.ndarray):\n",
        "        temp[i] = temp[i].mean()\n",
        "\n",
        "train = pd.DataFrame(train.merge(pd.DataFrame(temp), on='author', suffixes=(\n",
        "    '', '_mode_author'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0']))\n",
        "del temp\n",
        "\n",
        "\n",
        "# Ajout moyenne ups des réponse au commentaire père\n",
        "train['Unnamed: 0'] = train.index\n",
        "train = pd.DataFrame(train.merge(train[['ups', 'parent_id']].groupby(['parent_id']).mean(\n",
        "), on='parent_id', suffixes=('', '_mean_ans_parent')).sort_values(['Unnamed: 0']).set_index(['Unnamed: 0']))\n",
        "\n",
        "\n",
        "# Ajout mode ups des réponse au commentaire père\n",
        "train['Unnamed: 0'] = train.index\n",
        "temp = train[['ups', 'parent_id']].groupby(\n",
        "    ['parent_id'])['ups'].agg(pd.Series.mode)\n",
        "for i in temp.index:\n",
        "    if isinstance(temp[i], np.ndarray):\n",
        "        temp[i] = temp[i].mean()\n",
        "\n",
        "train = pd.DataFrame(train.merge(pd.DataFrame(temp), on='parent_id', suffixes=(\n",
        "    '', '_mode_ans_parent'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0']))\n",
        "del temp\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------\n",
        "# Partie test\n",
        "# Ajout moyenne ups author\n",
        "test['Unnamed: 0'] = test.index\n",
        "test = test.merge(train[['ups', 'author']].groupby(['author']).mean(), on='author', suffixes=(\n",
        "    '', '_mean_author'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "# Ajout mode ups author\n",
        "test['Unnamed: 0'] = test.index\n",
        "\n",
        "temp = train[['ups', 'author']].groupby(['author'])['ups'].agg(pd.Series.mode)\n",
        "len_temp = len(temp)\n",
        "for i in range(len_temp):\n",
        "    if type(temp[i]) is np.ndarray:\n",
        "        temp[i] = temp[i].mean()\n",
        "\n",
        "test = test.merge(pd.DataFrame(temp), on='author', suffixes=(\n",
        "    '', '_mode_author'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "del temp, len_temp\n",
        "\n",
        "# Ajout moyenne ups des réponse au commentaire père\n",
        "test['Unnamed: 0'] = test.index\n",
        "test = test.merge(train[['ups', 'parent_id']].groupby(['parent_id']).mean(), on='parent_id', suffixes=(\n",
        "    '', '_mean_ans_parent'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "# Ajout mode ups des réponse au commentaire père\n",
        "test['Unnamed: 0'] = test.index\n",
        "temp = train[['ups', 'parent_id']].groupby(\n",
        "    ['parent_id'])['ups'].agg(pd.Series.mode)\n",
        "for i in temp.index:\n",
        "    if isinstance(temp[i], np.ndarray):\n",
        "        temp[i] = temp[i].mean()\n",
        "\n",
        "test = test.merge(pd.DataFrame(temp), on='parent_id', suffixes=(\n",
        "    '', '_mode_ans_parent'), how='left').sort_values(['Unnamed: 0']).set_index(['Unnamed: 0'])\n",
        "\n",
        "del temp\n",
        "\n",
        "\n",
        "mean_author = train['ups_mean_author'].mean()\n",
        "mean_author_parent = train['ups_mean_ans_parent'].mean()\n",
        "#mod_author = train[['ups', 'author']].groupby(['author'])['ups'].agg(pd.Series.mode)\n",
        "#mod_author_parent = train[['ups','parent_id']].groupby(['parent_id'])['ups'].agg(pd.Series.mode)\n",
        "\n",
        "test['ups_mean_author'] = test['ups_mean_author'].fillna(mean_author)\n",
        "test['ups_mode_author'] = test['ups_mode_author'].fillna(1)\n",
        "test['ups_mean_ans_parent'] = test['ups_mean_ans_parent'].fillna(\n",
        "    mean_author_parent)\n",
        "test['ups_mode_ans_parent'] = test['ups_mode_ans_parent'].fillna(1)\n",
        "\n",
        "# On fussionne les dataframes\n",
        "df = pd.concat([train, test])\n",
        "\n",
        "del train, test\n",
        "\n",
        "# On ne garde que les features\n",
        "df['ups_mode_author'] = df['ups_mode_author'].astype('float')\n",
        "df['ups_mode_ans_parent'] = df['ups_mode_ans_parent'].astype('float')\n",
        "df = df[['ups_mean_author', 'ups_mean_ans_parent',\n",
        "         'ups_mode_author', 'ups_mode_ans_parent']]\n",
        "\n",
        "# Export feature\n",
        "df.to_csv(feature_dossier + \"mean_mod_author.csv\")\n",
        "\n",
        "del df, mean_author, mean_author_parent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lZ2lNyJNQAW"
      },
      "source": [
        "#### Creation de notre data frame totale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XDau87xKeT3",
        "outputId": "6a724a60-8d7c-4ce8-a247-ad1037dfa32b"
      },
      "source": [
        "# On prend les ups\n",
        "data_all_feature = pd.read_csv(comments_students)[['ups']]\n",
        "\n",
        "# Liste des chemins des features\n",
        "liste_feat = [feature_dossier + \"closeness.csv\",\n",
        "              feature_dossier + \"nb_comm_per_author.csv\",\n",
        "              feature_dossier + \"nb_mot_body.csv\",\n",
        "              feature_dossier + \"pop_post.csv\",\n",
        "              feature_dossier + \"sentiment_feature.csv\",\n",
        "              feature_dossier + \"time_feature.csv\",\n",
        "              feature_dossier + \"topic.csv\",\n",
        "              feature_dossier + \"mean_mod_author.csv\",\n",
        "              feature_dossier + \"post_comm.csv\",\n",
        "              feature_dossier + \"closeness_author.csv\",\n",
        "              feature_dossier + \"betweenness_centrality_author.csv\"]\n",
        "\n",
        "# On ajoute les dataframes un par un pour limiter l'impact sur la RAM\n",
        "for i in tqdm(liste_feat):\n",
        "    new_feat = pd.read_csv(i).drop(columns=['Unnamed: 0'])\n",
        "    data_all_feature = pd.concat([data_all_feature, new_feat], axis=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11/11 [00:24<00:00,  2.23s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sFMYYFZURXl"
      },
      "source": [
        "data_all_feature = pd.concat([data_all_feature, df[\"nombreDescendants\",\"nombreEnfants\",\"ratioEnfantsDescendants\"]], axis=1)\n",
        "# On export le csv avec toutes les features\n",
        "\n",
        "data_all_feature.to_csv(feature_dossier + \"data_all_feature.csv\")\n",
        "\n",
        "del data_all_feature, liste_feat, new_feat, i,df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvl8f29ngaCr"
      },
      "source": [
        "# **PARTIE 2 :** Entraînement du modèle et prédictions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usmXQkQXNDaB"
      },
      "source": [
        "#### Chargement de notre data frame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_BqkLr2NC8g"
      },
      "source": [
        "# Chargement des features et separation entre train et test\n",
        "df = pd.read_csv(feature_dossier + \"data_all_feature.csv\").drop(columns=['Unnamed: 0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CURMpD9hRoQs"
      },
      "source": [
        "### Séparation des données train et test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYubZd_QqC1f"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVpk-FWY-zAp"
      },
      "source": [
        "## on a obtenu le score le plus optimale avec ces features\n",
        "list_feat_T=['close_cent', 'link_new_id','Topic','bet_cent_aut','pop_post','time_answer','time_1st_comment_post','nb_com_aut','nombreDescendants','nombreEnfants','ratioEnfantsDescendants']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXo63P7MTXiu"
      },
      "source": [
        "# x_train/x_test\n",
        "train = df[~np.isnan(df['ups'])]\n",
        "x_train = train[list_feat_T]\n",
        "y_train = pd.DataFrame(train['ups'])\n",
        "test = df[np.isnan(df['ups'])]\n",
        "x_test = test[list_feat_T]\n",
        "del df,train,list_feat_T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjdCm-hx9F8L"
      },
      "source": [
        "### Entrainement du modele"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFLRv799T-DL",
        "outputId": "52997322-c1b5-41dc-a300-53228a1fa753"
      },
      "source": [
        "# entrainemenet du modele avec les parametres les plus optimaux trouvé\n",
        "reg = GradientBoostingRegressor(loss='huber',criterion='friedman_mse',random_state=0,max_features='log2',n_estimators=500)\n",
        "reg.fit(x_train,y_train)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='huber',\n",
              "                          max_depth=3, max_features='log2', max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=0, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiKn3Q-19Jxp"
      },
      "source": [
        "### Prediction et extraction du csv finale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SNj48CjYr02"
      },
      "source": [
        "y_test=reg.predict(x_test)\n",
        "y_pred = pd.DataFrame(y_test)\n",
        "y_pred.index = x_test.index\n",
        "y_pred.columns = ['predicted']\n",
        "# On récupère l'id des commentaires à prédire avec ups et on l'ajoute aux ups predites précédemment\n",
        "df_fin = df_fin[np.isnan(df_fin['ups'])]\n",
        "df_fin = df_fin.drop('ups', axis=1)\n",
        "df_fin = pd.concat([df_fin, y_pred], axis=1)\n",
        "df_fin.columns = ['id', 'predicted']\n",
        "\n",
        "# Export du csv (penser à changer la version pour ne pas écraser un fichier csv précédent)\n",
        "\n",
        "df_fin.to_csv(\"/content/drive/MyDrive/kaggle Project/Donnéespred_ups_5.csv\", sep=',', index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
